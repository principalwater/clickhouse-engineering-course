# Домашнее задание №13: Storage Policy и резервное копирование

---

## Оглавление
- [Описание задания и цели](#описание-задания-и-цели)
- [Архитектура решения и аппаратное обеспечение](#архитектура-решения-и-аппаратное-обеспечение)
  - [Сценарий 1: Локальное хранение + Удаленный бэкап](#сценарий-1-локальное-хранение--удаленный-бэкап)
  - [Сценарий 2: S3-хранение + Удаленный бэкап](#сценарий-2-s3-хранение--удаленный-бэкап)
- [Часть 1. Развертывание и бэкап с локальным хранилищем](#часть-1-развертывание-и-бэкап-с-локальным-хранилищем)
- [Часть 2. Переключение на S3-хранилище](#часть-2-переключение-на-s3-хранилище)
- [Часть 3. Анализ альтернативных конфигураций](#часть-3-анализ-альтернативных-конфигураций)
- [Общие выводы по заданию](#общие-выводы-по-заданию)
- [Список источников](#список-источников)

---

## Описание задания и цели
В данном домашнем задании будут рассмотрены механизмы управления хранением данных с помощью `Storage Policy` и обеспечение их сохранности через резервное копирование на S3. Будут реализованы и сравнены два подхода к хранению основных данных: на локальном SSD и на S3-совместимом хранилище.

---

## Архитектура решения и аппаратное обеспечение
Для выполнения задания используется гибридная, полностью автоматизированная архитектура, описанная в модуле [`base-infra/ch_with_backup`](../base-infra/ch_with_backup/README.md).

### Аппаратное обеспечение
-   **Хост-машина (`mac-studio-foxes-home.local`):**
    -   **Модель:** Mac Studio (2023)
    -   **Процессор:** Apple M2 Max
    -   **Память:** 32 ГБ
    -   **Накопитель (основной):** Встроенный SSD Apple
-   **Внешний накопитель (локальный S3):**
    -   **Модель:** Samsung Portable SSD T7
    -   **Объем:** 2 ТБ
    -   **Подключение:** Thunderbolt 4
-   **Удаленный сервер (`water-rpi.local`):**
    -   **Модель:** Raspberry Pi 5
    -   **Память:** 8 ГБ
    -   **Накопитель (для бэкапов):** Samsung PM991a NVMe 512 ГБ (подключен через PCIe)
    -   **ОС:** Debian 12 (Bookworm)

### Сценарий 1: Локальное хранение + Удаленный бэкап
-   **Данные ClickHouse:** Хранятся на локальном SSD хост-машины (`mac-studio-foxes-home.local`). Это обеспечивает максимальную производительность для "горячих" данных.
-   **Резервные копии:** Сохраняются на удаленный сервер `water-rpi.local` в S3-хранилище MinIO.

### Сценарий 2: S3-хранение + Удаленный бэкап
-   **Данные ClickHouse:** Хранятся на "локальном" S3-хранилище MinIO, которое развернуто на внешнем SSD Samsung T7, подключенном к хост-машине. Этот сценарий демонстрирует разделение `compute` и `storage`.
-   **Резервные копии:** Также сохраняются на удаленный сервер `water-rpi.local`.

---

## Часть 1. Развертывание и бэкап с локальным хранилищем

1.  **Развертывание:**
    Запускаем конфигурацию по умолчанию (`storage_type = "local_ssd"`).
    ```sh
    cd base-infra/ch_with_backup
    terraform apply -auto-approve
    ```
2.  **Создание и наполнение таблицы:**
    ```sql
    CREATE TABLE default.sample_table ON CLUSTER dwh_test (id UInt64, data String)
    ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/sample_table', '{replica}') ORDER BY id;
    INSERT INTO default.sample_table SELECT number, randomString(10) FROM numbers(1000);
    ```
3.  **Резервное копирование:**
    Выполняется с помощью `clickhouse-backup` на S3 (MinIO на `water-rpi.local`).
    ```bash
    docker exec clickhouse-backup clickhouse-backup create backup_local_storage
    ```
4.  **Восстановление:**
    После удаления таблицы (`DROP TABLE default.sample_table ON CLUSTER dwh_test;`), восстановление выполняется командой:
    ```bash
    docker exec clickhouse-backup clickhouse-backup restore backup_local_storage
    ```
*Результаты выполнения шагов для Сценария 1:*

<img src="../screenshots/hw13_storage-policy-backup/01_scenario_local.png" alt="Сценарий 1" width="800"/>

---

## Часть 2. Переключение на S3-хранилище

1.  **Переконфигурация и развертывание:**
    Уничтожаем предыдущую конфигурацию и разворачиваем новую, указав `storage_type = "s3_ssd"`.
    ```sh
    terraform destroy -auto-approve
    terraform apply -var="storage_type=s3_ssd" -auto-approve
    ```
2.  **Создание таблицы с `Storage Policy`:**
    Теперь при создании таблицы явно указываем политику `s3_main`, чтобы данные хранились на локальном S3 (внешний SSD).
    ```sql
    CREATE TABLE default.sample_table_s3 ON CLUSTER dwh_test (id UInt64, data String)
    ENGINE = ReplicatedMergeTree('/clickhouse/tables/{shard}/sample_table_s3', '{replica}')
    ORDER BY id
    SETTINGS storage_policy = 's3_main';
    INSERT INTO default.sample_table_s3 SELECT number, randomString(10) FROM numbers(1000);
    ```
3.  **Проверка хранения данных:**
    Запрос к `system.parts` покажет, что данные таблицы `sample_table_s3` хранятся на диске `s3_cache`.
    ```sql
    SELECT name, disk_name FROM system.parts WHERE table = 'sample_table_s3' LIMIT 5;
    ```
4.  **Резервное копирование и восстановление:**
    Процесс бэкапа и восстановления аналогичен Сценарию 1, но теперь мы бэкапим таблицу, данные которой уже находятся в S3.

*Результаты выполнения шагов для Сценария 2:*

<img src="../screenshots/hw13_storage-policy-backup/02_scenario_s3.png" alt="Сценарий 2" width="800"/>

---

## Часть 3. Анализ альтернативных конфигураций

На базе имеющегося оборудования возможны и другие интересные конфигурации:
-   **Hot/Cold Storage:** Можно настроить `Storage Policy`, которая будет хранить "горячие" данные (например, за последний месяц) на быстром локальном SSD, а "холодные" — автоматически перемещать на более медленный, но объемный S3 (внешний SSD или удаленный сервер).
-   **Бэкап на локальный S3:** В случае отсутствия удаленного сервера, можно развернуть MinIO на внешнем SSD и использовать его и для хранения данных, и для бэкапов, разнеся их по разным бакетам.
-   **Полностью удаленное хранилище:** Для максимального разделения `compute` и `storage` можно настроить ClickHouse так, чтобы он хранил все данные, включая метаданные, на удаленном S3. Это усложняет настройку, но дает максимальную гибкость в масштабировании.

---

## Общие выводы по заданию
(Этот раздел будет дополнен позже)

---

## Список источников
- [Официальная документация ClickHouse: Политики хранения данных](https://clickhouse.com/docs/ru/engines/table-engines/mergetree-family/mergetree#table_engine-mergetree-multiple-volumes)
- [Репозиторий Altinity/clickhouse-backup](https://github.com/Altinity/clickhouse-backup)
